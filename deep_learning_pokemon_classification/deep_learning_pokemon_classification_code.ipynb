{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLJCtV1NfDR"
      },
      "source": [
        "# Pokémon Classification with Deep Learning Applications\n",
        "*   Mert Çalışkan\n",
        "*   Zübeyir Faruk Tekbaş"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8jRsCSZN3Lw"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNCoGGTRmRha",
        "outputId": "fd31a7ac-0038-49e0-9ade-e512a55b9508"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input, BatchNormalization, Activation, LeakyReLU, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from math import ceil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VByu7zEeN6Pi"
      },
      "source": [
        "## Data Set Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI8krOm2XLqx"
      },
      "outputs": [],
      "source": [
        "data_dir = 'images'\n",
        "csv_file = 'pokemon.csv'\n",
        "pokemon_data = pd.read_csv(csv_file)\n",
        "pokemon_data['image_path'] = pokemon_data['Name'].apply(lambda x: f'{data_dir}/{x}.png')\n",
        "pokemon_data['label'] = pokemon_data['Type1'].astype('category').cat.codes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R97glH7OCca"
      },
      "source": [
        "## Data Analysis and Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(pokemon_data.isnull().sum())\n",
        "\n",
        "pokemon_data.drop(columns=[\"Type2\", \"Evolution\"], inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS8ALan_ZknE"
      },
      "outputs": [],
      "source": [
        "pokemon_data['image'] = pokemon_data['image_path'].apply(lambda path: img_to_array(load_img(path, target_size=(120, 120))) / 255.0)\n",
        "images = np.stack(pokemon_data['image'].values)\n",
        "labels = to_categorical(pokemon_data['label'].values)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decoding\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_train_original = decode_labels(np.argmax(y_train, axis=1), pokemon_data)\n",
        "y_val_original = decode_labels(np.argmax(y_val, axis=1), pokemon_data)\n",
        "y_test_original = decode_labels(np.argmax(y_test, axis=1), pokemon_data)\n",
        "\n",
        "pokemon_data['Type1_decoded'] = decode_labels(pokemon_data['label'], pokemon_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeWbUcSuGu_q",
        "outputId": "2e1d1bae-b046-4b66-8eeb-788d3ff7b71b"
      },
      "outputs": [],
      "source": [
        "print(y_train.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWkW7HYBFt75"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "batch_size = 32\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(pokemon_data['Type1'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the values in the 'Type1' column\n",
        "type_counts = pokemon_data['Type1'].value_counts()\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=type_counts, y=type_counts.index, palette=\"viridis\")\n",
        "plt.xlabel('Pokémon Count')\n",
        "plt.ylabel('Type1')\n",
        "for i, count in enumerate(type_counts):\n",
        "    plt.text(count, i, f' {count}', va='center')\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "b12aIHwQTmpd",
        "outputId": "7ba2dc16-dbcb-4d15-ce81-0f045be2cd4d"
      },
      "outputs": [],
      "source": [
        "num_images = 16\n",
        "random_indices = np.random.choice(len(images), num_images, replace=False)\n",
        "fig, axes = plt.subplots(2, 8, figsize=(12, 4))\n",
        "for ax, idx in zip(axes.flat, random_indices):\n",
        "    ax.imshow(images[idx])\n",
        "    ax.axis('off')\n",
        "    ax.set_title(f\"{pokemon_data['Type1'][idx]}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GePSZfEu3I-w"
      },
      "source": [
        "## MLP Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zswwz_Je3BD"
      },
      "outputs": [],
      "source": [
        "results = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_mlp_basic = Sequential([\n",
        "    Input(shape=(120, 120, 3)),  # Giriş katmanı\n",
        "    Flatten(),\n",
        "    Dense(512),\n",
        "    Activation('relu'),\n",
        "    Dense(256),\n",
        "    Activation('relu'),\n",
        "    Dense(len(np.unique(pokemon_data['Type1'])), activation='softmax') \n",
        "])\n",
        "\n",
        "model_mlp_basic.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp_basic.summary()\n",
        "\n",
        "# Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-8, verbose=1)\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "history_mlp_basic = model_mlp_basic.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_mlp_basic.history['accuracy']\n",
        "val_acc = history_mlp_basic.history['val_accuracy']\n",
        "train_loss = history_mlp_basic.history['loss']\n",
        "val_loss = history_mlp_basic.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_mlp_basic.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation metrics\n",
        "y_pred_mlp_basic = model_mlp_basic.predict(X_test)\n",
        "y_pred_classes_mlp_basic = np.argmax(y_pred_mlp_basic, axis=1)\n",
        "y_true_mlp_basic = np.argmax(y_test, axis=1)\n",
        "accuracy_mlp_basic = accuracy_score(y_true_mlp_basic, y_pred_classes_mlp_basic)\n",
        "precision_mlp_basic = precision_score(y_true_mlp_basic, y_pred_classes_mlp_basic, average='weighted', zero_division=0)\n",
        "recall_mlp_basic = recall_score(y_true_mlp_basic, y_pred_classes_mlp_basic, average='weighted')\n",
        "f1_mlp_basic = f1_score(y_true_mlp_basic, y_pred_classes_mlp_basic, average='weighted')\n",
        "results.append({'Model': 'MLP Basic', 'Accuracy': accuracy_mlp_basic, 'Precision': precision_mlp_basic, 'Recall': recall_mlp_basic, 'F1 Score': f1_mlp_basic})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_mlp_basic.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_mlp1 = Sequential([\n",
        "    Input(shape=(120, 120, 3)),\n",
        "    Flatten(),\n",
        "    Dense(32, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4), kernel_initializer=HeNormal()),\n",
        "    Activation('relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4), kernel_initializer=HeNormal()),\n",
        "    Activation('relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(np.unique(pokemon_data['Type1'])), activation='softmax') \n",
        "])\n",
        "\n",
        "model_mlp1.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp1.summary()\n",
        "\n",
        "# Callback \n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-8, verbose=1)\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "history_mlp1 = model_mlp1.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_mlp1.history['accuracy']\n",
        "val_acc = history_mlp1.history['val_accuracy']\n",
        "train_loss = history_mlp1.history['loss']\n",
        "val_loss = history_mlp1.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_mlp1.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_mlp1 = model_mlp1.predict(X_test)\n",
        "y_pred_classes_mlp1 = np.argmax(y_pred_mlp1, axis=1)\n",
        "y_true_mlp1 = np.argmax(y_test, axis=1)\n",
        "accuracy_mlp1 = accuracy_score(y_true_mlp1, y_pred_classes_mlp1)\n",
        "precision_mlp1 = precision_score(y_true_mlp1, y_pred_classes_mlp1, average='weighted', zero_division=0)\n",
        "recall_mlp1 = recall_score(y_true_mlp1, y_pred_classes_mlp1, average='weighted')\n",
        "f1_mlp1 = f1_score(y_true_mlp1, y_pred_classes_mlp1, average='weighted')\n",
        "results.append({'Model': 'MLP1', 'Accuracy': accuracy_mlp1, 'Precision': precision_mlp1, 'Recall': recall_mlp1, 'F1 Score': f1_mlp1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_mlp1.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_mlp2 = Sequential([\n",
        "    Input(shape=(120, 120, 3)),\n",
        "    Flatten(),\n",
        "    Dense(32, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4), kernel_initializer=HeNormal()),  \n",
        "    Activation('relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4), kernel_initializer=HeNormal()), \n",
        "    Activation('relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(np.unique(pokemon_data['Type1'])), activation='softmax')\n",
        "])\n",
        "\n",
        "model_mlp2.compile(optimizer=RMSprop(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp2.summary()\n",
        "\n",
        "# Define Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-8, verbose=1)\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "# Start the Training\n",
        "history_mlp2 = model_mlp2.fit(\n",
        "    train_generator,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_mlp2.history['accuracy']\n",
        "val_acc = history_mlp2.history['val_accuracy']\n",
        "train_loss = history_mlp2.history['loss']\n",
        "val_loss = history_mlp2.history['val_loss']\n",
        "\n",
        "# List containing epoch numbers\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "# Calculate and print test accuracy and loss\n",
        "test_loss, test_acc = model_mlp2.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_mlp2 = model_mlp2.predict(X_test)\n",
        "y_pred_classes_mlp2 = np.argmax(y_pred_mlp2, axis=1)\n",
        "y_true_mlp2 = np.argmax(y_test, axis=1)\n",
        "accuracy_mlp2 = accuracy_score(y_true_mlp2, y_pred_classes_mlp2)\n",
        "precision_mlp2 = precision_score(y_true_mlp2, y_pred_classes_mlp2, average='weighted', zero_division=0)\n",
        "recall_mlp2 = recall_score(y_true_mlp2, y_pred_classes_mlp2, average='weighted')\n",
        "f1_mlp2= f1_score(y_true_mlp2, y_pred_classes_mlp2, average='weighted')\n",
        "results.append({'Model': 'MLP2', 'Accuracy': accuracy_mlp2, 'Precision': precision_mlp2, 'Recall': recall_mlp2, 'F1 Score': f1_mlp2})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_mlp2.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssAyQCyV3Dzj"
      },
      "source": [
        "### MLP3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "_fQa7gb39P5d",
        "outputId": "097f2fb2-d4df-4338-cf83-5a958da24f64"
      },
      "outputs": [],
      "source": [
        "model_mlp3 = Sequential([\n",
        "    Input(shape=(120, 120, 3)), \n",
        "    Flatten(),                \n",
        "    Dense(1024),              \n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(512),              \n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(256),            \n",
        "    BatchNormalization(),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(len(np.unique(pokemon_data['Type1'])), activation='softmax')\n",
        "])\n",
        "\n",
        "model_mlp3.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp3.summary()\n",
        "# Callback \n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-8, verbose=1)\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "history_mlp3 = model_mlp3.fit(\n",
        "    train_generator,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_mlp3.history['accuracy']\n",
        "val_acc = history_mlp3.history['val_accuracy']\n",
        "train_loss = history_mlp3.history['loss']\n",
        "val_loss = history_mlp3.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_mlp3.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_mlp3 = model_mlp3.predict(X_test)\n",
        "y_pred_classes_mlp3 = np.argmax(y_pred_mlp3, axis=1)\n",
        "y_true_mlp3 = np.argmax(y_test, axis=1)\n",
        "accuracy_mlp3 = accuracy_score(y_true_mlp3, y_pred_classes_mlp3)\n",
        "precision_mlp3 = precision_score(y_true_mlp3, y_pred_classes_mlp3, average='weighted', zero_division=0)\n",
        "recall_mlp3 = recall_score(y_true_mlp3, y_pred_classes_mlp3, average='weighted')\n",
        "f1_mlp3 = f1_score(y_true_mlp3, y_pred_classes_mlp3, average='weighted')\n",
        "results.append({'Model': 'MLP3', 'Accuracy': accuracy_mlp3, 'Precision': precision_mlp3, 'Recall': recall_mlp3, 'F1 Score': f1_mlp3})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_mlp3.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ces6WefSUj1"
      },
      "source": [
        "### MLP4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFxRzku1SVIg"
      },
      "outputs": [],
      "source": [
        "model_mlp4 = Sequential([\n",
        "    Input(shape=(120, 120, 3)),\n",
        "    Flatten(),    \n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model_mlp4.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_mlp4.summary()\n",
        "\n",
        "# Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-8)\n",
        "\n",
        "history_mlp4 = model_mlp4.fit(\n",
        "    train_generator,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_mlp4.history['accuracy']\n",
        "val_acc = history_mlp4.history['val_accuracy']\n",
        "train_loss = history_mlp4.history['loss']\n",
        "val_loss = history_mlp4.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_mlp4.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_mlp4 = model_mlp4.predict(X_test)\n",
        "y_pred_classes_mlp4 = np.argmax(y_pred_mlp4, axis=1)\n",
        "y_true_mlp4 = np.argmax(y_test, axis=1)\n",
        "accuracy_mlp4 = accuracy_score(y_true_mlp4, y_pred_classes_mlp4)\n",
        "precision_mlp4 = precision_score(y_true_mlp4, y_pred_classes_mlp4, average='weighted', zero_division=0)\n",
        "recall_mlp4 = recall_score(y_true_mlp4, y_pred_classes_mlp4, average='weighted')\n",
        "f1_mlp4 = f1_score(y_true_mlp4, y_pred_classes_mlp4, average='weighted')\n",
        "results.append({'Model': 'MLP4', 'Accuracy': accuracy_mlp4, 'Precision': precision_mlp4, 'Recall': recall_mlp4, 'F1 Score': f1_mlp4})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_mlp4.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CNN Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN Basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn_basic = Sequential([\n",
        "    Input(shape=(120, 120, 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn_basic.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn_basic.summary()\n",
        "\n",
        "# Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-8, verbose=1)\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "history_cnn_basic = model_cnn_basic.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_cnn_basic.history['accuracy']\n",
        "val_acc = history_cnn_basic.history['val_accuracy']\n",
        "train_loss = history_cnn_basic.history['loss']\n",
        "val_loss = history_cnn_basic.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_cnn_basic.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_cnn_basic = model_cnn_basic.predict(X_test)\n",
        "y_pred_classes_cnn_basic = np.argmax(y_pred_cnn_basic, axis=1)\n",
        "y_true_cnn_basic = np.argmax(y_test, axis=1)\n",
        "accuracy_cnn_basic = accuracy_score(y_true_cnn_basic, y_pred_classes_cnn_basic)\n",
        "precision_cnn_basic = precision_score(y_true_cnn_basic, y_pred_classes_cnn_basic, average='weighted', zero_division=0)\n",
        "recall_cnn_basic = recall_score(y_true_cnn_basic, y_pred_classes_cnn_basic, average='weighted')\n",
        "f1_cnn_basic = f1_score(y_true_cnn_basic, y_pred_classes_cnn_basic, average='weighted')\n",
        "results.append({'Model': 'CNN Basic', 'Accuracy': accuracy_cnn_basic, 'Precision': precision_cnn_basic, 'Recall': recall_cnn_basic, 'F1 Score': f1_cnn_basic})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_cnn_basic.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mDw4MaTFt78"
      },
      "source": [
        "### CNN1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5sDZGjhFt78"
      },
      "outputs": [],
      "source": [
        "model_cnn1 = Sequential([\n",
        "    Input(shape=(120, 120, 3)),\n",
        "    Conv2D(16, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_cnn1.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_cnn1.summary()\n",
        "# Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-8, verbose=1)\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "history_cnn1 = model_cnn1.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=callbacks\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_cnn1.history['accuracy']\n",
        "val_acc = history_cnn1.history['val_accuracy']\n",
        "train_loss = history_cnn1.history['loss']\n",
        "val_loss = history_cnn1.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_cnn1.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_cnn1 = model_cnn1.predict(X_test)\n",
        "y_pred_classes_cnn1 = np.argmax(y_pred_cnn1, axis=1)\n",
        "y_true_cnn1 = np.argmax(y_test, axis=1)\n",
        "accuracy_cnn1 = accuracy_score(y_true_cnn1, y_pred_classes_cnn1)\n",
        "precision_cnn1 = precision_score(y_true_cnn1, y_pred_classes_cnn1, average='weighted', zero_division=0)\n",
        "recall_cnn1 = recall_score(y_true_cnn1, y_pred_classes_cnn1, average='weighted')\n",
        "f1_cnn1 = f1_score(y_true_cnn1, y_pred_classes_cnn1, average='weighted')\n",
        "results.append({'Model': 'CNN1', 'Accuracy': accuracy_cnn1, 'Precision': precision_cnn1, 'Recall': recall_cnn1, 'F1 Score': f1_cnn1})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_cnn1.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = VGG16(include_top=False, input_shape=(120, 120, 3), weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_cnn2 = Sequential([\n",
        "    base_model,\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),\n",
        "    #BatchNormalization(),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn2.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-8, verbose=1)\n",
        "\n",
        "history_cnn2 = model_cnn2.fit(\n",
        "    train_generator,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "model_cnn2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_cnn2.history['accuracy']\n",
        "val_acc = history_cnn2.history['val_accuracy']\n",
        "train_loss = history_cnn2.history['loss']\n",
        "val_loss = history_cnn2.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_cnn2.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_cnn2 = model_cnn2.predict(X_test)\n",
        "y_pred_classes_cnn2 = np.argmax(y_pred_cnn2, axis=1)\n",
        "y_true_cnn2 = np.argmax(y_test, axis=1)\n",
        "accuracy_cnn2 = accuracy_score(y_true_cnn2, y_pred_classes_cnn2)\n",
        "precision_cnn2 = precision_score(y_true_cnn2, y_pred_classes_cnn2, average='weighted', zero_division=0)\n",
        "recall_cnn2 = recall_score(y_true_cnn2, y_pred_classes_cnn2, average='weighted')\n",
        "f1_cnn2 = f1_score(y_true_cnn2, y_pred_classes_cnn2, average='weighted')\n",
        "results.append({'Model': 'CNN2', 'Accuracy': accuracy_cnn2, 'Precision': precision_cnn2, 'Recall': recall_cnn2, 'F1 Score': f1_cnn2})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_cnn2.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_model = VGG16(include_top=False, input_shape=(120, 120, 3), weights='imagenet')\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model_cnn3 = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.02)),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.02)),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn3.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-8, verbose=1)\n",
        "\n",
        "history_cnn3 = model_cnn3.fit(\n",
        "    train_generator,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "model_cnn3.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_cnn3.history['accuracy']\n",
        "val_acc = history_cnn3.history['val_accuracy']\n",
        "train_loss = history_cnn3.history['loss']\n",
        "val_loss = history_cnn3.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_cnn3.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_cnn3 = model_cnn3.predict(X_test)\n",
        "y_pred_classes_cnn3 = np.argmax(y_pred_cnn3, axis=1)\n",
        "y_true_cnn3 = np.argmax(y_test, axis=1)\n",
        "accuracy_cnn3 = accuracy_score(y_true_cnn3, y_pred_classes_cnn3)\n",
        "precision_cnn3 = precision_score(y_true_cnn3, y_pred_classes_cnn3, average='weighted', zero_division=0)\n",
        "recall_cnn3 = recall_score(y_true_cnn3, y_pred_classes_cnn3, average='weighted')\n",
        "f1_cnn3 = f1_score(y_true_cnn3, y_pred_classes_cnn3, average='weighted')\n",
        "results.append({'Model': 'CNN3', 'Accuracy': accuracy_cnn3, 'Precision': precision_cnn3, 'Recall': recall_cnn3, 'F1 Score': f1_cnn3})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_cnn3.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_cnn4 = Sequential([\n",
        "    Input(shape=(120, 120, 3)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "model_cnn4.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-8, verbose=1)\n",
        "\n",
        "history_cnn4 = model_cnn4.fit(\n",
        "    train_generator,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=200,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "model_cnn4.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_acc = history_cnn4.history['accuracy']\n",
        "val_acc = history_cnn4.history['val_accuracy']\n",
        "train_loss = history_cnn4.history['loss']\n",
        "val_loss = history_cnn4.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "test_loss, test_acc = model_cnn4.evaluate(X_test, y_test)\n",
        "print(f'Training Accuracy: {train_acc[-1]}')\n",
        "print(f'Validation Accuracy: {val_acc[-1]}')\n",
        "print(f'Test Accuracy: {test_acc}')\n",
        "print(f'Training Loss: {train_loss[-1]}')\n",
        "print(f'Validation Loss: {val_loss[-1]}')\n",
        "print(f'Test Loss: {test_loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Training and Validation Accuracy Plot\n",
        "plt.plot(epochs, train_acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n",
        "\n",
        "# Training and Validation Loss Plot\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(visible=None)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_cnn4 = model_cnn4.predict(X_test)\n",
        "y_pred_classes_cnn4 = np.argmax(y_pred_cnn4, axis=1)\n",
        "y_true_cnn4 = np.argmax(y_test, axis=1)\n",
        "accuracy_cnn4 = accuracy_score(y_true_cnn4, y_pred_classes_cnn4)\n",
        "precision_cnn4 = precision_score(y_true_cnn4, y_pred_classes_cnn4, average='weighted', zero_division=0)\n",
        "recall_cnn4 = recall_score(y_true_cnn4, y_pred_classes_cnn4, average='weighted')\n",
        "f1_cnn4 = f1_score(y_true_cnn4, y_pred_classes_cnn4, average='weighted')\n",
        "results.append({'Model': 'CNN4', 'Accuracy': accuracy_cnn4, 'Precision': precision_cnn4, 'Recall': recall_cnn4, 'F1 Score': f1_cnn4})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred_probs = model_cnn4.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "def decode_labels(labels, pokemon_data):\n",
        "    type_mapping = dict(enumerate(pokemon_data['Type1'].astype('category').cat.categories))\n",
        "    return np.vectorize(type_mapping.get)(labels)\n",
        "\n",
        "y_pred_labels = decode_labels(y_pred_classes, pokemon_data)\n",
        "y_true_labels = decode_labels(y_true_classes, pokemon_data)\n",
        "\n",
        "# Confusion Matrixn\n",
        "conf_matrix = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_true_labels), yticklabels=np.unique(y_true_labels))\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdyn7YCJih9h"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtRwY0DkfNVw"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
